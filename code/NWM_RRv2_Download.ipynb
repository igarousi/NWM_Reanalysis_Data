{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the Simulated Retrospective Reanalysis Data of the National Water Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook downloads the National Water Model (NWM) retrospective reanalysis data. The NWM reanalysis data are large NetCDF files and are stored within a scratch directory. The ouput directory contains a csv file that shows NWM grid indices associated with each SNOTEL gage. This csv file will be used later in other scripts to retrieve different variables (such as snow water equivalent, snow covered area, ...) at SNOTEL locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "In this section, required python libraries are installed and imported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "import netCDF4        # pip install netCDF4 \n",
    "import xarray as xr   # pip install xarray \n",
    "import pyproj         # pip install pyproj \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Read SNOTEL Information and Define Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '../input'                                           # The path to the CSV file including the SNOTEL sites information\n",
    "output_dir = '../output'                                         # The path to save CSV files including indices, SWE, and Precipitation values. \n",
    "\n",
    "dataset = 'LDASOUT'                                              # The type of the NWM output.  LDASOUT is the output of the land surface model.\n",
    "st = '2007-01-01'                                                # Start date of the period of interest\n",
    "et = '2007-01-02'                                                # End date of the period of interest\n",
    "Glist = 'GoogleList.txt'                                         # The name of a file including full path to the NWM data\n",
    "data_dir='/oasis/projects/nsf/usu104/igarousi/projects/scratch'  # The path to download the NWM data\n",
    "\n",
    "nrcs_file = \"NRCS_SNOTEL_no_Alaska_Joint_w_CEC.csv\"              # This is an input. A csv file that includes information about SNOTEL sites\n",
    "nwm_file = \"201801010300.LDASOUT_DOMAIN1.comp\"                   # This is an input. A netcdf file that is the result of land surface model in NWM.\n",
    "variable = 'SNEQV'                                               # The variable of interest as used in the NWM\n",
    "output_name = 'SNOTEL_indices_at_NWM.csv'                        # The name for output in Get_NWM_indices function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Generate a List of Full Paths to NWM Data\n",
    "The following cell will create a list of `gs://national-water-model-v2/full_physics/*` into 'GoogleList.txt' file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(st, et, freq='1H')\n",
    "\n",
    "# Create full paths and append to Gname list\n",
    "Gname = []\n",
    "for d in dates:\n",
    "\n",
    "    google_name = f'gs://national-water-model-v2/full_physics/{d.year}/{d.year}{str(d.month).zfill(2)}{str(d.day).zfill(2)}{str(d.hour).zfill(2)}{str(d.minute).zfill(2)}.{dataset}_DOMAIN1.comp'\n",
    "    Gname.append(google_name)\n",
    "\n",
    "# Save as a text file  \n",
    "with open(os.path.join(output_dir, Glist), 'w') as f:\n",
    "    for i in Gname:\n",
    "        if i != Gname[-1]:   # this is because I don't want a new empty line at the end of the file\n",
    "            f.write(i+'\\n')\n",
    "        else:\n",
    "            f.write(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Download the NWM Data Using `gsutil` Library\n",
    "\n",
    "The gsutil library needs to be installed if it is not installed yet. The following batch script installs gsutil. Note that the file should exist in code directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gsutil_install.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command save results (i.e., downloaded netcdf files) at a scratch directory that exist on the top-level directory. The size of files are large and you need to make sure that you have enough storage. I have ~ 1.5 TB storage on my project directory. This is not enought becasue for 12 year of data I need ~ 8.5 TB. So, what I do is to choose small periods in the second cell above, download data, and then move them to the comet scratch directory where I have more storage to save files temporarily. After the analysis is done, I will delet these files. **Question**: Why don't I save them on comet scratch directory the first place? Because, I get OSError: Read-only file system error! \n",
    "\n",
    "Note that the temporal resolution of the land surface model outputs for retrospective configuration is 3-hour.  That is why we get \"No URLs matched ...\" message for several hours after running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gsutil_run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to move files to `/oasis/scratch/comet/igarousi/temp_project` becasue this path will be used in the next scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  Define a Function to Get Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes SNOTEL sites information and the projection coordinate system from a NWM file as inputs and retrives X and Y indices for each SNOTEL site. The output of this function is a csv file that includes information of NWM indices for each SNOTEL site. This will be used as an input to the Get_NWM_values function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_NWM_indices(input_dir, nrcs_file, nwm_file, output_dir, output_name):\n",
    "\n",
    "    '''\n",
    "    input_dir   : Input path where the nrcs_file (snotel information) and NWM (ldasout example) exist. \n",
    "    nrcs_file   : A csv file that includes information about SNOTEL sites.\n",
    "    nwm_file    : A netcdf file that is the result of land surface model in NWM.\n",
    "    Y_NWM       : An array holding Y indices of the NWM grid cells.\n",
    "    X_NWM       : An array holding X indices of NWM grid cells.\n",
    "    output_dir : Path to save a csv file as the output of this function. \n",
    "                  It incldues useful information about SNOTEL sites most importantly the associated \n",
    "                  indices that are used to retrieve NWM variales later. \n",
    "    '''\n",
    "    \n",
    "    Data=pd.DataFrame([])\n",
    "    \n",
    "    # Use the site information and generate a dataframe \n",
    "    nrcs = pd.read_csv(os.path.join(input_dir, nrcs_file))\n",
    "    \n",
    "    # Open the example NWM file and read the projection. \n",
    "    # Then, create a projection using pyproj libarary and using 'crs' information from the above object\n",
    "    nwm_example = netCDF4.Dataset(os.path.join(input_dir, nwm_file))\n",
    "    pr = pyproj.Proj(nwm_example.variables['crs'].esri_pe_string)\n",
    "    \n",
    "    # Open the example NWM file and read  X and Y indices of all grids from one NWM file\n",
    "    nc_NWM = xr.open_dataset(os.path.join(input_dir, nwm_file))\n",
    "    X_NWM = nc_NWM.coords['x']\n",
    "    Y_NWM = nc_NWM.coords['y']\n",
    "    \n",
    "    # Loop over the sites\n",
    "    for i in range(0, len(nrcs['Station_ID'])):\n",
    "        \n",
    "        # Generate projected values (proj_y and proj_x) from latitude and longitude of SNOTEL gages \n",
    "        # Note: in pr, the first element should be longitude and the second is latitude\n",
    "        # Note: results of pr, the first element is x and the second is y\n",
    "        proj_x, proj_y = pr(nrcs['Longitude'][i], nrcs['Latitude'][i])\n",
    "        \n",
    "        # Calculate the distance between the center of grids from the location of the site\n",
    "        distance = ((Y_NWM - proj_y)**2 + (X_NWM - proj_x)**2)**0.5\n",
    "        yindex, xindex = np.where(distance == distance.min())\n",
    "                                  \n",
    "        # Create a dataframe\n",
    "        data = pd.DataFrame({'col1': nrcs['Station_ID'][i],\n",
    "                             'col2': nrcs['Station_Na'][i], \n",
    "                             'col3': nrcs['NAME'][i],\n",
    "                             'col4': nrcs['Longitude'][i], \n",
    "                             'col5': nrcs['Latitude'][i],\n",
    "                             'col6': proj_x, \n",
    "                             'col7': proj_y, \n",
    "                             'col8': xindex, \n",
    "                             'col9': yindex})\n",
    "                                  \n",
    "        # create a dataframe\n",
    "        frames = [Data, data]\n",
    "        Data = pd.concat(frames, ignore_index=True)\n",
    "        \n",
    "                                  \n",
    "    # Save dataframe as a csv file\n",
    "    Data.columns = ['Station_ID', 'Station_Name', 'Ecoregion_NAME', 'Longitude', 'Latitude', 'proj_x', 'proj_y', 'Xindex', 'Yindex']\n",
    "    Data.to_csv(os.path.join(output_dir, output_name), index=False)\n",
    "                                  \n",
    "    \n",
    "    return Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.  Run the Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve location indices and show available variales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Site_Info = Get_NWM_indices(input_dir, nrcs_file, nwm_file, output_dir, output_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
