{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process the Retrieved CSV Files from NWM Retrospective NetCDF Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook uses results from NWM_RRv2_Retrieve.py (i.e., zipped CSV files) to create single CSV for specified variables. For example, it reads NWM_2007_ALBEDO.zip, NWM_2008_ALBEDO.zip, ... and ouptuts NWM_ALBEDO.csv. Then, it will filter the complete dataset using a specified period and pattern (structure) to create a dataframe. This is becasue I want to have the same time period for NWM, SNOTEL, and SNODAS comparision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../output'                # The path including zipped cvs files\n",
    "output_dir = data_dir                 # The path to save final csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Manipulate NWM Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip NWM results and create a single CSV file for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in glob.glob(os.path.join(data_dir, \"*.zip\")):\n",
    "    \n",
    "    with zipfile.ZipFile(f, 'r') as ref:\n",
    "        \n",
    "        ref.extractall(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, read all csv files and create a combined csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['ALBEDO', 'ALBSND', 'ALBSNI', 'COSZ', 'FIRA', \n",
    "             'FSA', 'FSNO', 'HFX', 'LH', 'SNEQV', 'SNOWH', 'TRAD']\n",
    "\n",
    "for v in variables:\n",
    "    \n",
    "    all_filenames = [i for i in glob.glob(os.path.join(data_dir, f'NWM_*_*_{v}.csv'))]\n",
    "    combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames])\n",
    "    combined_csv.to_csv(os.path.join(output_dir, f'NWM_{v}.csv'), index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Filter Dataset for a Specific Time Period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Read Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "snotel_info = pd.read_csv(os.path.join(output_dir, 'SNOTEL_indices_at_NWM.csv'))\n",
    "\n",
    "# put the data that you received from NCAR in output_dir and name it NWM_P.csv\n",
    "nwm_p = pd.read_csv(os.path.join(output_dir, 'NWM_P.csv'))                       \n",
    "\n",
    "for v in variables:\n",
    "    vars()[f'nwm_{v}'] = pd.read_csv(os.path.join(output_dir, f'NWM_{v}.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Define a Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_Hourly = pd.date_range('2007-01-01', '2007-04-01', freq='1H')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Define Filter Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function loops over all sites and for each day in the dates_Hourly list, it extracts the values of snow water equivalent (LDASOUT outputs) or precipitation (FORCING iputs)  as well as some other information related to the gage. Finally, it returns a dataframe including 4 columns (Site_ID, Ecoregion_Name, Date_Time_UTC, and variale of interest) as the output. \n",
    "\n",
    "Note that if precipitation is the varibale of interest, some pre-processing should be done for inputs to the Filter function becasue precipitation values are note retrieved using developed scripts. I asked for them from NWM support team at NCAR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter(dataset1, dataset2, column_code, column_val, final_column_val, csv_name, output_dir):\n",
    "    \n",
    "    '''\n",
    "    dataset1:          Dataset for which Filter function is used  \n",
    "    dataset2:          Dataset including snotel information\n",
    "    column_code:       Column including station id\n",
    "    column_val:        Column including values of the variable of interest\n",
    "    final_column_val:  Column including values of the variable of interests as results \n",
    "    csv_name:          Name of the output (i.e., a CSV file)\n",
    "    output_dir:        Path to save outputs\n",
    "    '''\n",
    "    \n",
    "    # Get station ids\n",
    "#     code = set(dataset1[column_code])  # List of site codes \n",
    "    code = [301, 1000]\n",
    "    \n",
    "    ID = []\n",
    "    NAME = []\n",
    "    TIME = []\n",
    "    VALUE = []\n",
    "    for c in code:\n",
    "        select = dataset1.loc[dataset1[column_code] == c]\n",
    "        for d in dates_Hourly:\n",
    "            try:\n",
    "                id = select[pd.to_datetime(select['time']) == d][column_code].values[0]\n",
    "                name = dataset2[dataset2[column_code] == c]['Ecoregion_NAME'].values[0]\n",
    "                value = select[pd.to_datetime(select['time']) == d][column_val].values[0]\n",
    "            except Exception as e:\n",
    "                value = np.nan\n",
    "            ID.append(id)\n",
    "            NAME.append(name)\n",
    "            TIME.append(d)\n",
    "            VALUE.append(value)\n",
    "\n",
    "    df = pd.DataFrame({'col1': ID, 'col2': NAME, 'col3': TIME, 'col4': VALUE})\n",
    "    df.columns = ['Site_Code',  'Ecoregion_Name', 'Date_Time_UTC', final_column_val] \n",
    "    df.index = df['Date_Time_UTC']\n",
    "    df.to_csv(os.path.join(output_dir, csv_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Apply Filter Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables in LDASOUT\n",
    "\n",
    "for v in variables:\n",
    "    \n",
    "    dataset1 = vars()[f'nwm_{v}']         \n",
    "    dataset2 = vars()['snotel_info'] \n",
    "    column_code = 'Station_ID'\n",
    "    column_val = dataset1.columns[4]\n",
    "    final_column_val = dataset1.columns[4]\n",
    "    csv_name = f'NWM_{v}_Filter.csv'\n",
    "\n",
    "    Filter(dataset1, dataset2, column_code, column_val, final_column_val, csv_name, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precipitation\n",
    "\n",
    "dataset1 = vars()['nwm_p']       \n",
    "dataset1.rename(columns={'site_id':'Station_ID'}, inplace=True)                   # change the column name to be consistent with snotel_info\n",
    "dataset1['time'] = pd.to_datetime(dataset1['time'], format='%Y%m%d%H')            # make 'time' column as a data/time format \n",
    "dataset2 = vars()['snotel_info'] \n",
    "column_code = 'Station_ID'\n",
    "column_val = 'P'\n",
    "final_column_val = 'P_mm'\n",
    "csv_name = 'NWM_P_Filter.csv'\n",
    "\n",
    "Filter(dataset1, dataset2, column_code, column_val, final_column_val, csv_name, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
